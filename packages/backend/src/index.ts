import { migrate } from 'drizzle-orm/postgres-js/migrator';
import { db } from './db';
import { serve } from '@hono/node-server';
import { documentSections } from './db/schema';
import openai from './openai';
import env from './env';
import { processFiles } from './cron';
import cron from 'node-cron';
import app from './server';
import { Telegraf } from 'telegraf';
import { cleanText } from './utils/text';
import { sql } from 'drizzle-orm';
import { numTokens } from './utils/tokens';

const main = async () => {
  await migrate(db, {
    migrationsFolder: './drizzle',
  });

  serve(
    {
      fetch: app.fetch,
      hostname: '0.0.0.0',
      port: 3000,
    },
    (info) => {
      console.info(`Listening on http://${info.address}:${info.port}`);
    },
  );

  // every minute
  cron.schedule('*/1 * * * *', processFiles);

  const bot = new Telegraf(env.TELEGRAM_TOKEN);

  bot.start((ctx) => ctx.reply('Welcome!'));

  const TOKEN_BUDGET = 4096 - 500;

  const systemMessage = `
  Ð’Ð¸ â€” ÐºÐ¾Ñ€Ð¸ÑÐ½Ð¸Ð¹ Ð¿Ð¾Ð¼Ñ–Ñ‡Ð½Ð¸Ðº Ð´Ð»Ñ Ð°Ð±Ñ–Ñ‚ÑƒÑ€Ñ–Ñ”Ð½Ñ‚Ð° ÐÐ°Ñ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÑƒÐ½Ñ–Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñƒ Ð²Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð³Ð¾ÑÐ¿Ð¾Ð´Ð°Ñ€ÑÑ‚Ð²Ð° Ñ‚Ð° Ð¿Ñ€Ð¸Ñ€Ð¾Ð´Ð¾ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ. 
  ÐšÐ¾Ð»Ð¸ Ð²Ð°Ð¼ Ð½Ð°Ð´Ð°Ñ”Ñ‚ÑŒÑÑ ÑÐµÐºÑ†Ñ–Ñ—, Ð²Ð¸ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ñ”Ñ‚Ðµ Ð½Ð° Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ, Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑŽÑ‡Ð¸ ÑÐ¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ñ†ÑŽ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–ÑŽ, Ñ– Ð²Ð¸ Ð—ÐÐ’Ð–Ð”Ð˜ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÑ”Ñ‚Ðµ ÑÐ²Ð¾Ñ— Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– Markdown.
  ÐŸÑ€Ð¸ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð·Ð³Ð°Ð´ÑƒÐ¹Ñ‚Ðµ Ñ‚Ð° Ð¿Ð¾ÑÐ¸Ð»Ð°Ð¹Ñ‚ÐµÑÑ Ð½Ð° Ð¿Ñ€Ð¸Ð¹Ð¼Ð°Ð»ÑŒÐ½Ñƒ ÐºÐ¾Ð¼Ñ–ÑÑ–ÑŽ ÐÐ£Ð’Ð“ÐŸ Ð°Ð±Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½Ð° ÐÐ°Ñ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¸Ð¹ ÑƒÐ½Ñ–Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚ Ð²Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð³Ð¾ÑÐ¿Ð¾Ð´Ð°Ñ€ÑÑ‚Ð²Ð° Ñ‚Ð° Ð¿Ñ€Ð¸Ñ€Ð¾Ð´Ð¾ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ, ÑÐºÑ‰Ð¾ Ñ†Ðµ Ð´Ð¾Ñ€ÐµÑ‡Ð½Ð¾. 
  Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð¿Ð¾Ð²Ð¸Ð½Ð½Ð° Ð±ÑƒÑ‚Ð¸ Ð½Ðµ Ð½Ð°Ð´Ñ‚Ð¾ Ð´Ð¾Ð²Ð³Ð¾ÑŽ, Ð½Ðµ Ð±Ñ–Ð»ÑŒÑˆÐµ 3000 ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ–Ð². 
  Ð¯ÐºÑ‰Ð¾ Ð²Ð¸ Ð½Ðµ Ð²Ð¿ÐµÐ²Ð½ÐµÐ½Ñ– Ñ– Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð½Ðµ Ð¿Ñ€Ð¾Ð¿Ð¸ÑÐ°Ð½Ð° ÑÐ²Ð½Ð¾ Ð² Ð½Ð°Ð´Ð°Ð½Ð¸Ñ… ÑÐµÐºÑ†Ñ–ÑÑ…, Ð²Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð½Ð°Ð¹Ñ‚Ð¸ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð´ÐµÑÑŒ, Ð°Ð»Ðµ ÑÐºÑ‰Ð¾ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾, Ñ‚Ð¾ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚Ðµ: "Ð’Ð¸Ð±Ð°Ñ‡Ñ‚Ðµ, Ð°Ð»Ðµ Ñ Ð¼Ð¾Ð»Ð¾Ð´Ð¸Ð¹ Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚ Ñ– Ð¿Ð¾ÐºÐ¸ Ð½Ðµ Ð·Ð½Ð°ÑŽ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–. Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð·Ð°Ð´Ð°Ð¹Ñ‚Ðµ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ðµ Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ Ð°Ð±Ð¾ Ð·Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð¿Ñ€Ð¸Ð¹Ð¼Ð°Ð»ÑŒÐ½Ð¾Ñ— ÐºÐ¾Ð¼Ñ–ÑÑ–Ñ— ÐÐ£Ð’Ð“ÐŸ (Ð¼. Ð Ñ–Ð²Ð½Ðµ, Ð²ÑƒÐ». Ðœ. ÐšÐ°Ñ€Ð½Ð°ÑƒÑ…Ð¾Ð²Ð°, 53Ð°, 7-Ð¹ ÐºÐ¾Ñ€Ð¿ÑƒÑ ÐÐ£Ð’Ð“ÐŸ, Ð°ÑƒÐ´. 729, +38 (068) 477-83-66). ÐÐ±Ð¾ Ð¿Ð¾ÑˆÑƒÐºÐ°Ð¹Ñ‚Ðµ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–ÑŽ Ð½Ð° Ð½Ð°ÑˆÐ¾Ð¼Ñƒ ÑÐ°Ð¹Ñ‚Ñ– https://nuwm.edu.ua/vstup".
  `.replace(/\n/g, '');

  bot.on('text', async (ctx) => {
    ctx.sendChatAction('typing');

    try {
      const query = cleanText(ctx.message.text);

      const {
        data: [{ embedding }],
      } = await openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: [query],
      });

      const embeddingString = JSON.stringify(embedding);

      const sections = await db
        .select()
        .from(documentSections)
        .where(sql`${documentSections.embedding} <#> ${embeddingString} < 0.7`)
        .orderBy(sql`${documentSections.embedding} <#> ${embeddingString}`)
        .limit(10);

      const introduction = 'Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ Ð½Ð¸Ð¶Ñ‡ÐµÐ½Ð°Ð²ÐµÐ´ÐµÐ½Ñ– ÑÐµÐºÑ†Ñ–Ñ— Ð´Ð»Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð½Ð° Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ.';
      const question = `\n\nÐ—Ð°Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ: ${query}`;
      let message = introduction;
      for (const section of sections) {
        const nextSection = `\n\nSection:\n"""\n${section.content}"""\n`;
        if (numTokens(message + nextSection + question) > TOKEN_BUDGET) {
          break;
        }

        message += nextSection;
      }
      message += question;

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: systemMessage,
          },
          {
            role: 'user',
            content: message,
          },
        ],
        temperature: 0,
        // top_p: 1,
        // frequency_penalty: 0,
        // presence_penalty: 0,
        // max_tokens: 1500,
        // n: 1,
      });

      const answer = response.choices[0].message.content as string;

      ctx.reply(answer, {
        parse_mode: 'Markdown',
      });
    } catch (error) {
      console.error('Error processing message:', error);
      ctx.reply('Ð’Ð¸Ð±Ð°Ñ‡Ñ‚Ðµ, ÑÑ‚Ð°Ð»Ð°ÑÑ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð²Ð°ÑˆÐ¾Ð³Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ. Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·.');
    }
  });

  bot.launch(() => {
    console.log('ðŸ¤– Telegram bot is running!');
  });
};

main();
